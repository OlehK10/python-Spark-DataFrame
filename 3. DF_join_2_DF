"""
added a function join_table
"""

from datetime import datetime, date
from functools import wraps
from pyspark.sql import DataFrame
import pyspark
from pyspark.sql import SparkSession
import pyspark.sql.functions as F
from pyspark.sql.functions import udf
from pyspark.sql.functions import col
from pyspark.sql.types import IntegerType, StructType, StructField, StringType, DateType, FloatType



class AdsVentureCount():
    app_name = 'Grand'
    # ----Table 1
    data1 = [("1", "Kharkov Filial", "Kharkov"),
             ("2", "Kiev Filial", "Kiev",),
             ("3", "Dnepr Filial", "Dnepr",),
             ("4", "Lviv Filial", "Lviv"),
             ("5", "New Filial", "Lviv")]
    columns1 = ["DEPTNO", "DNAME", "LOC"]
    #----Table 2
    data2 = [("1", "Ivanov", "head filial", None, date(1995,12,16), 100000, 1),
             ("2", "Petrov", "meneger", "1", date(2000,11,16), 50000, 1),
             ("3", "Sidorov", "developer", "1", date(2010,9,16), 50000, 1),
             ("4", "Sidorov2", "developer", "1", date(2011,12,16), 45000, 1),
             ("5", "Sidorov3", "head filial", None, date(2005,12,16), 145000, 2),
             ("7", "Sidorov4", "meneger", "5", date(2015,10,16), 50000, 2),
             ("8", "Sidorov5", "developer", "5", date(1992,3,16), 85000, 2),
             ("9", "Sidorov6", "head filial", None, date(2020,12,16), 95000, 3),
             ("10", "Sidorov7", "meneger", "9", date(2021,12,16), 135000, 3),
             ("11", "Sidorov8", "head filial", "1", date(2022,6,16), 75000, 4)]
    # columns2 = StructType(["EMPNO", "ENAME", "JOB", "MGR", "HIREDATE", "SAL", "DEPTNO"])
    columns2 = StructType( \
        [\
            StructField("EMPNO", StringType(),True), \
            StructField("ENAME", StringType(),True), \
            StructField("JOB", StringType(),True), \
            StructField("MGR", StringType(),True), \
            StructField("HIREDATE", DateType(),True), \
            StructField("SAL", IntegerType(), True), \
            StructField("DEPTNO", IntegerType(),True) \
        ])
    def ct_time(func):
        """
        added a decorator that counts the execution time of the run function
        :return:
        """
        @wraps(func)
        def inner(*args, **kwargs):
            start = datetime.now()
            tmp = func(*args, **kwargs)
            ct_tm = datetime.now() - start
            print("count_time: ", ct_tm)
            return tmp

        return inner

    @ct_time
    def run(self):

        spark = SparkSession.builder.appName(self.app_name).getOrCreate()
        DEPT = spark.createDataFrame(self.data1, self.columns1)
        EMP = spark.createDataFrame(self.data2, self.columns2)
        DEPT.show()
        EMP.show()
        # ---- change_name_columns

        DEPT = AdsVentureCount.change_name_columns(DEPT, 'DEPT_')
        EMP = AdsVentureCount.change_name_columns(EMP, 'EMP_')
        print('DEPT_')
        DEPT.show()
        print('EMP_')
        EMP.show()
        # ----join 2 Table
        source_df = AdsVentureCount.join_table(DEPT, EMP, DEPT['DEPT_DEPTNO'] == EMP['EMP_DEPTNO'])
        source_df.show()

    @staticmethod
    def change_name_columns(VAR_DF: DataFrame, PREFIX_: str) -> DataFrame:
        """
        :param VAR_DF: :DataFrame
        :param PREFIX_: : string <- the word to be added before the given column name
        -------
        :returns : DataFrame

        -------
        -------
        Examples

            VAR_DF : DataFrame

            PREFIX_: DEPT_ <- the word to be added before the given column name

        input:
            ============ ==========
            DEPTNO          EMP
            ============ ==========
                      1        4
                      2        3
            ============ ==========

        out : DataFrame
            ============ ==========
            DEPT_DEPTNO  DEPT_EMP
            ============ ==========
                      1        4
                      2        3
            ============ ==========
        """

        for column in VAR_DF.columns:
            # print('column = ', column)
            new_column = column.replace(column, PREFIX_ + column)
            VAR_DF = VAR_DF.withColumnRenamed(column, new_column)

        return VAR_DF

    @staticmethod
    def join_table(DEPT: DataFrame, EMP: DataFrame, joinExpression) -> DataFrame:

        df_new = DEPT.join(EMP, joinExpression, 'leftouter')

        return df_new

if __name__ == '__main__':
    job = AdsVentureCount()
    job.run()
